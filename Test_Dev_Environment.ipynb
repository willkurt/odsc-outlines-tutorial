{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8d65d8f-e189-4a2d-b190-7568933ffaba",
   "metadata": {},
   "source": [
    "# Testing Your Dev Environment\n",
    "\n",
    "The purpose of this notebook is to ensure that your development environment for this workshop is setup correctly.\n",
    "\n",
    "## Basic Libraries\n",
    "\n",
    "Let's start by making sure all of the libraries are installed correctly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39697032-a6fe-4342-a50a-5185df3ee3ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-16T05:29:43.182439Z",
     "iopub.status.busy": "2024-08-16T05:29:43.182314Z",
     "iopub.status.idle": "2024-08-16T05:29:44.493511Z",
     "shell.execute_reply": "2024-08-16T05:29:44.493248Z",
     "shell.execute_reply.started": "2024-08-16T05:29:43.182431Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import outlines\n",
    "import llama_cpp\n",
    "import torch\n",
    "from transformers import AutoTokenizer\n",
    "from textwrap import dedent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b102c66-24f2-4b51-b232-288e9def0cdb",
   "metadata": {},
   "source": [
    "## Loading models\n",
    "\n",
    "This tutorial was built using `Phi-3-medium-4k-instruct` but this can be too large for most laptops/notebook environments. To assist there are several models avaible that should run, quantized, fine enough for even the most resource constrained laptop. \n",
    "\n",
    "- `Hermes-2-Pro-Llama-3-8B`: Reasonable Mid-sized model.\n",
    "- `Qwen2-0.5B-Instruct`: The results will be a bit odd, but this is quantized version will only require ~350 MB so this should work for anyone.\n",
    "\n",
    "For doing the exercises the size of the model is not important, but you will get better outcomes with more powerful models. Change the `MODEL_NAME` variable in each notebook to set the desired model. Make sure the following code runs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75d9d55e-8dad-4c47-8e80-3cdb766b9464",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-16T05:30:44.096453Z",
     "iopub.status.busy": "2024-08-16T05:30:44.095680Z",
     "iopub.status.idle": "2024-08-16T05:30:44.103142Z",
     "shell.execute_reply": "2024-08-16T05:30:44.102126Z",
     "shell.execute_reply.started": "2024-08-16T05:30:44.096396Z"
    }
   },
   "outputs": [],
   "source": [
    "MODEL_NAME = 'Phi-3-medium-4k-instruct'\n",
    "\n",
    "with open(\"./model_meta.json\") as meta_file:\n",
    "    MODEL_META = json.load(meta_file)\n",
    "\n",
    "MODEL = MODEL_META[MODEL_NAME]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5495164-2aa0-49a1-9dfa-277227fd39d2",
   "metadata": {},
   "source": [
    "The next bit of code will initialize the mode:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31252076-d9da-48dd-8cf2-1a04c84a8ee8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-16T05:29:44.990605Z",
     "iopub.status.busy": "2024-08-16T05:29:44.990253Z",
     "iopub.status.idle": "2024-08-16T05:29:45.830732Z",
     "shell.execute_reply": "2024-08-16T05:29:45.830445Z",
     "shell.execute_reply.started": "2024-08-16T05:29:44.990581Z"
    }
   },
   "outputs": [],
   "source": [
    "llama_tokenizer = llama_cpp.llama_tokenizer.LlamaHFTokenizer.from_pretrained(MODEL['tokenizer_repo'])\n",
    "model = outlines.models.llamacpp(\n",
    "            MODEL['repo_id'],\n",
    "            MODEL['file_name'],\n",
    "            tokenizer=llama_tokenizer)\n",
    "\n",
    "tokenizer = llama_tokenizer.hf_tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d67cd2f8-812c-4751-a597-5061c52468aa",
   "metadata": {},
   "source": [
    "Then we create a simple prompt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66e755c8-36eb-4d06-a991-f2ecec8904ac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-15T21:44:41.101084Z",
     "iopub.status.busy": "2024-08-15T21:44:41.100670Z",
     "iopub.status.idle": "2024-08-15T21:44:41.120706Z",
     "shell.execute_reply": "2024-08-15T21:44:41.120107Z",
     "shell.execute_reply.started": "2024-08-15T21:44:41.101052Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|im_start|>system\\nYou are a helpful assistant.<|im_end|>\\n<|im_start|>user\\nGenerate a phone number<|im_end|>\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Generate a phone number\"\n",
    "    },\n",
    "]\n",
    "\n",
    "prompt = tokenizer.apply_chat_template(messages, tokenize=False)\n",
    "prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a4f375d-f8a9-4b82-883b-ba42714136cf",
   "metadata": {},
   "source": [
    "## Unstructured Generation\n",
    "\n",
    "This code will test *unstructured* generation with outlines. If you can run this in a reasonable amount of time you have selected the appropiate sized model for you laptop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "957a0b08-5198-4c3e-9ab7-ffc3b816eee8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-15T21:44:43.592450Z",
     "iopub.status.busy": "2024-08-15T21:44:43.591947Z",
     "iopub.status.idle": "2024-08-15T21:44:43.596694Z",
     "shell.execute_reply": "2024-08-15T21:44:43.595869Z",
     "shell.execute_reply.started": "2024-08-15T21:44:43.592421Z"
    }
   },
   "outputs": [],
   "source": [
    "generator = outlines.generate.text(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8ca5118-6532-41e9-b989-c62c2808126f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-15T21:44:43.887172Z",
     "iopub.status.busy": "2024-08-15T21:44:43.886451Z",
     "iopub.status.idle": "2024-08-15T21:44:44.267677Z",
     "shell.execute_reply": "2024-08-15T21:44:44.267402Z",
     "shell.execute_reply.started": "2024-08-15T21:44:43.887146Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|im_start|>software\\nTo generate a phone number, please provide the following information:\\n\\n\\n * Does the number come from the United'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator(prompt,max_tokens=24)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a6f6e0-4234-4cb7-8f55-a3c34ed9c7ee",
   "metadata": {},
   "source": [
    "## Structured Generation\n",
    "\n",
    "Finally we run an example using *structured* generation. If you can run this code, then everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c6db5ce-035c-46ae-a849-4ed4b6d2016b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-15T21:44:44.523253Z",
     "iopub.status.busy": "2024-08-15T21:44:44.522783Z",
     "iopub.status.idle": "2024-08-15T21:44:44.642556Z",
     "shell.execute_reply": "2024-08-15T21:44:44.642250Z",
     "shell.execute_reply.started": "2024-08-15T21:44:44.523227Z"
    }
   },
   "outputs": [],
   "source": [
    "generator_struct = outlines.generate.regex(model, r\"\\([0-9]{3}\\) [0-9]{3}-[0-9]{4}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e057800c-066e-43a2-9620-51e3a40a9029",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-15T21:35:29.793664Z",
     "iopub.status.busy": "2024-08-15T21:35:29.793573Z",
     "iopub.status.idle": "2024-08-15T21:35:30.003472Z",
     "shell.execute_reply": "2024-08-15T21:35:30.003161Z",
     "shell.execute_reply.started": "2024-08-15T21:35:29.793655Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(192) 496-1211'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator_struct(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1798a7-cb06-4cbf-8d4c-2e0979208ac8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
