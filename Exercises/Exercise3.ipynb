{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ab7cafe-b712-4794-b4a6-69186eaf411c",
   "metadata": {},
   "source": [
    "# Exercise 3: Generating Complaints and the Structured Generation Workflow\n",
    "\n",
    "For this exercise we're going to work on a much more involved example. When creating this workshop I didn't want to have to hand write 50 complaints, so I decided to let an LLM do that for me! Typically we would think of a complain as *unstructured* but, as you can see in this exercise, there's almost always an advantage to using structured generation. \n",
    "\n",
    "The code for this exercise is a fair be more involved than the last two, but don't worry, you only need to work on a small part of this project.\n",
    "\n",
    "We're also going to learn about the [Structured Generation Workflow](https://blog.dottxt.co/coding-for-structured-generation.html) which make it easier to iteratively develop structured applications using LLMs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a3aa6ec-89e8-4832-a008-823b099ffd0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import outlines\n",
    "from transformers import AutoTokenizer\n",
    "import torch\n",
    "from textwrap import dedent\n",
    "from enum import Enum\n",
    "import re\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e5116b-4bb8-4108-931e-2e8a4e0c0273",
   "metadata": {},
   "source": [
    "**Note:** change the `DEVICE` if you are using a non-Apple Silicon device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce7d7b5-e75c-46de-b51a-1cd9d3c23faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"Qwen/Qwen2-0.5B-Instruct\"\n",
    "# Change to 'cuda' or 'cpu' if not using Apple Silicon\n",
    "DEVICE='mps'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb98ffb-f6a6-4d83-8463-219785926f61",
   "metadata": {},
   "source": [
    "For consistency, we'll be using the Enum from the last exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b4b016-4b96-4ba2-8ac2-cd09839df327",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Department(str, Enum):\n",
    "    clothing = \"clothing\"\n",
    "    electronics = \"electronics\"\n",
    "    kitchen = \"kitchen\"\n",
    "    automotive = \"automotive\"\n",
    "\n",
    "DEFAULT_DEPTS = [dept.name for dept in list(Department)]\n",
    "DEFAULT_DEPTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de090770-a552-4507-9ef6-c9a6d0385b2f",
   "metadata": {},
   "source": [
    "## Step 1 - Draft Structure\n",
    "\n",
    "Our `ComplaintGenerator` builds complaints by breaking the complaint down into 3 steps with accompanying methods.\n",
    "\n",
    "- `intro_structure` contains the name of the person\n",
    "- `complaint_structure` contains the body of the complaint\n",
    "- `order_number_structure` gives the order number in several different ways.\n",
    "\n",
    "For this exercise we'll focus on the **intro_structure** and fill out the rest as time permits.\n",
    "\n",
    "\n",
    "All structured generation tasks, just like normal machine learnings tasks, should start with some *examples of real data*. Let's take a look at a few complaints (pretending for this exercise that these aren't generated and are real):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35be45c-00fd-477e-b205-2a6ae1c7a8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../examples.json\",'r') as fin:\n",
    "    complaint_data = json.loads(fin.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "275e5e1e-3ce7-4771-a407-22868b081197",
   "metadata": {},
   "source": [
    "Let's look at some example intros:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69c36e1-3f5b-47bd-a3d6-8b8abba4dfe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_intros = [complaint['message'][0:10] for complaint in complaint_data]\n",
    "set(example_intros)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff1f1a12-2a9a-4d8a-bab0-758d9465d09d",
   "metadata": {},
   "source": [
    "As we can see there are only two intros (in real life we would of course expect many more), but this helps us start to imagine the patterns we would like to generate.\n",
    "\n",
    "We'll use this to draft a version of the `intro_structure` method as our first step for structured generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e487036-4fdc-418c-86d8-289117179063",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "class ComplaintGenerator:\n",
    "\n",
    "    def __init__(self, model_name, departments=DEFAULT_DEPTS):\n",
    "        self.model_name = model_name\n",
    "        self.departments = departments\n",
    "        self._model = None\n",
    "        self._tokenizer = None\n",
    "        self._intro_generator = None\n",
    "        self._complaint_generator = None\n",
    "        self._order_number_generator = None\n",
    "    ####################################\n",
    "    # Structured Generation Section\n",
    "    #\n",
    "    @property\n",
    "    def intro_structure(self):\n",
    "        # TODO - find and fix the bug\n",
    "        possible_intros = [\n",
    "            r'(Hi! This is [A-Z][a-z]{3,10} [A-z][a-z]{3,10})',\n",
    "            r'(Hey, my name is [A-z][a-z]{3,10} [A-Z][a-z]{3,10})',\n",
    "            r'(Hello, I\\'m [A-Z][a-z]{3,10} [A-z][a-z]{3,10})'\n",
    "        ]\n",
    "        return rf\"({'|'.join(possible_intros)})\\.\"        \n",
    "\n",
    "    @property\n",
    "    def complaint_structure(self):\n",
    "        # TODO - implement the complaint structure\n",
    "        return r''\n",
    "\n",
    "    @property\n",
    "    def order_number_structure(self):\n",
    "        # TODO - implement a few variations on order number\n",
    "        possible_order_numbers = [\n",
    "             r'',\n",
    "             r'',\n",
    "             r''\n",
    "         ]\n",
    "        return rf\"({'|'.join(possible_order_numbers)})\"\n",
    "    #\n",
    "    #\n",
    "    ####################################\n",
    "\n",
    "    \n",
    "    @property\n",
    "    def intro_generator(self):\n",
    "        if self._intro_generator is None:\n",
    "            self._intro_generator = outlines.generate.regex(\n",
    "                self.model, self.intro_structure\n",
    "            )\n",
    "        return self._intro_generator\n",
    "        \n",
    "    @property\n",
    "    def complaint_generator(self):\n",
    "        if self._complaint_generator is None:\n",
    "            self._complaint_generator = outlines.generate.regex(self.model, self.complaint_structure)\n",
    "        return self._complaint_generator\n",
    "\n",
    "    @property\n",
    "    def order_number_generator(self):\n",
    "        if self._order_number_generator is None:\n",
    "            self._order_number_generator = outlines.generate.regex(\n",
    "                self.model, \n",
    "                self.order_number_structure)\n",
    "        return self._order_number_generator\n",
    "    \n",
    "    @property\n",
    "    def model(self):\n",
    "        print(\"getting model\")\n",
    "        if self._model is None:\n",
    "            print(\"loading model\")\n",
    "            self._model = outlines.models.transformers(\n",
    "                    self.model_name,\n",
    "                    device=DEVICE,\n",
    "                    model_kwargs={\n",
    "                        'torch_dtype': torch.bfloat16,\n",
    "                        'trust_remote_code': True\n",
    "                    })\n",
    "        return self._model\n",
    "\n",
    "    @property\n",
    "    def tokenizer(self):\n",
    "        if self._tokenizer is None:\n",
    "            print(\"loading tokenizer\")\n",
    "            self._tokenizer = AutoTokenizer.from_pretrained(self.model_name)\n",
    "        return self._tokenizer\n",
    "        \n",
    "    def generate_complaint(self):\n",
    "        prompt_messages = self._start_messages()\n",
    "        prompt_messages.append(self._intro_prompt())\n",
    "        prompt_intro = self.tokenizer.apply_chat_template(\n",
    "            prompt_messages,\n",
    "            tokenize=False\n",
    "        )\n",
    "        print(\"Generating intro\")\n",
    "        intro_result = self.intro_generator(prompt_intro)\n",
    "        prompt_messages.append({\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": intro_result\n",
    "        })\n",
    "        print(\"Generating complaint\")\n",
    "        department = random.choice(self.departments)\n",
    "        prompt_messages.append(self._complaint_prompt(department))\n",
    "        prompt_complaint = self.tokenizer.apply_chat_template(\n",
    "            prompt_messages,\n",
    "            tokenize=False\n",
    "        )\n",
    "        complaint_result = self.complaint_generator(prompt_complaint)\n",
    "        prompt_messages.append({\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": complaint_result\n",
    "        })\n",
    "        prompt_messages.append(self._order_number_prompt())\n",
    "        prompt_order_number = self.tokenizer.apply_chat_template(\n",
    "            prompt_messages,\n",
    "            tokenize=False\n",
    "        )\n",
    "        print(\"Generating order number\")\n",
    "        order_number_result = self.order_number_generator(prompt_order_number)\n",
    "\n",
    "        final_message = intro_result + complaint_result + order_number_result\n",
    "        return {\n",
    "            \"message\": final_message,\n",
    "            \"order_number\": self.parse_order_number(order_number_result),\n",
    "            \"department\": department\n",
    "        }\n",
    "    \n",
    "    def parse_order_number(self, message):\n",
    "        \"\"\"\n",
    "        We want to extract the order number so that we can \n",
    "        send it back with the response to use for validation later.\n",
    "        \"\"\"\n",
    "        number_only = r'((A|D|Z)[0-9]{6})|((A|D|Z)[0-9]{2}-[0-9]{4})'\n",
    "        order_number = re.search(number_only, message)[0]\n",
    "        if not (\"-\" in order_number):\n",
    "            order_number = f\"{order_number[0:3]}-{order_number[3:]}\"\n",
    "        return order_number\n",
    "        \n",
    "    def _start_messages(self):\n",
    "        \"\"\"\n",
    "        These are the starting prompt messages, since we'll be\n",
    "        appending to these messages, we'd like to return a \n",
    "        copy of them.\n",
    "        \"\"\"\n",
    "        prompt_messages = [{\n",
    "            \"role\": \"user\",\n",
    "            \"content\": dedent(\"\"\"\n",
    "            You are an agent designed to create simulated customer complaints. The\n",
    "            complaints are essentially short text messages that describe a customer,\n",
    "            their problem, and provide an order number.\n",
    "        \n",
    "            You will build the complaint in parts based on the user request. The\n",
    "            complaint will be about a product from a specified department, but you\n",
    "            will not mention the department name directly.\n",
    "        \n",
    "            For example, if you are asked about something from the 'kitchen' department \n",
    "            you might mention an 'knife' but you won't mention the department.\n",
    "            \"\"\")\n",
    "        },{ \n",
    "            \"role\": \"agent\",\n",
    "            \"content\": dedent(\"\"\"\n",
    "            I understand the task, and will wait for the you to instruct me on\n",
    "            next steps.\n",
    "            \"\"\")\n",
    "        }]\n",
    "        return(deepcopy(prompt_messages))\n",
    "\n",
    "    def _intro_prompt(self):\n",
    "        intro_prompt = {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Start the message with a short intro stating the customer's name.\"\n",
    "        }\n",
    "        return(deepcopy(intro_prompt))\n",
    "\n",
    "    def _complaint_prompt(self, department):\n",
    "        complaint_message = {\n",
    "            \"role\":\"user\", \n",
    "            \"content\": dedent(f\"\"\"\n",
    "                            Good! Now write a short description of the problem with an item from the {department} department,\n",
    "                            but don't mention the actual name of the department the product comes from!\n",
    "                            \"\"\")\n",
    "        }\n",
    "        return deepcopy(complaint_message)\n",
    "\n",
    "    def _order_number_prompt(self):\n",
    "        order_number_message = {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": dedent(\"\"\"\n",
    "            Finally, add a statement about the order number which starts with letter 'A', 'D' or 'Z' and consists of 6 digits after.\n",
    "            \"\"\")\n",
    "        }\n",
    "        return deepcopy(order_number_message)\n",
    "        \n",
    "    \n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4786ce1c-e879-486c-9e0c-2177ea952b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "complainer = ComplaintGenerator(MODEL_NAME)\n",
    "# complainer.generate_complaint()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12319f4b-6bdc-43c8-bfb6-4c759a9f8452",
   "metadata": {},
   "source": [
    "## Step 2 - Verify Structure \n",
    "\n",
    "We can now test that this structure indeed matches the real data we have. To start we're only going to test the `intro_structure` property. To help ensure that our structure is correct, we'll verify that our structure does indeed match *all* of the examples in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d61728e-e799-452d-aafb-b160f72db207",
   "metadata": {},
   "outputs": [],
   "source": [
    "all([re.search(complainer.intro_structure, complaint['message'])\n",
    "     for complaint in complaint_data])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bfc44a1-d99c-4b76-b7ad-2e1516f819e6",
   "metadata": {},
   "source": [
    "This is a great place to catch bugs in structured generation. Since we saw that all cases matched, we can at least be sure that our basic structure is correct."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f124e9-333c-4c36-bde4-01d7f3f2a21d",
   "metadata": {},
   "source": [
    "## Step 3 - Generate Structure\n",
    "\n",
    "The next step is to generate examples of our structure to further test whether or not we're really solving the problem we're after. Rather than run the model right now, we'll use an example I generated earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7219601-65af-4c11-afa6-9d5065da69b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normally we would do the following...\n",
    "# example_generation = complainer.generate()\n",
    "example_generation = {\n",
    " 'message': 'Hi! This is Emily andbuyerser.I recently ordered a laptop with an extended warranty, but upon arrival, I noticed a malfunctioning trackpad. Despite numerous attempts at troubleshooting, the issue persists, greatly hindering my everyday use.This is order A12-3456',\n",
    " 'order_number': 'A12-3456',\n",
    " 'department': 'electronics'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c734ff15-b8bd-4538-ab3c-9f5ac827879b",
   "metadata": {},
   "source": [
    "## Step 4 - Inspect Output\n",
    "\n",
    "Uh oh! Look at the name output! `Emily andbuyerser` is not a name that I would expect and doesn't match the expected output!\n",
    "\n",
    "Now it's *your turn* to fix it!\n",
    "\n",
    "When you've found the bug you can continue on to the next sections:\n",
    "\n",
    "- Finish the `complaint_structure`, repeating this process\n",
    "- Finish the `order_number_structure`, repeating this process\n",
    "- If you have time, generate some new complaints!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc671f6f-b3a9-46d4-933d-f3b70a7c3ca0",
   "metadata": {},
   "source": [
    "To help you get started, we can see current structure *does* match unexpected example output. A good sign that you have fixed the problem is that this erroneous response will no longer match the defined structure in `intro_structure`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3fc88a-a955-4d68-bf59-ed73c32d54cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "re.search(complainer.intro_structure, example_generation['message'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba9e63a-24c5-4381-9b0a-5d95a04686fe",
   "metadata": {},
   "source": [
    "If you get the rest figured out, feel free to generate some examples of your own!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18acbf60-f990-4bf3-bc9d-1bd2edc832af",
   "metadata": {},
   "outputs": [],
   "source": [
    "complaints = [complainer.generate_complaint() for _ in range(50)]\n",
    "complaints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e06bff-bc29-4bca-926e-d7754dd3c2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open(\"../examples.json\", 'w') as fout:\n",
    "#    fout.write(json.dumps(complaints))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
